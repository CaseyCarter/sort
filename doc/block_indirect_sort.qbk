[/===========================================================================
 Copyright (c) 2017 Steven Ross, Francisco Tapia, Orson Peters


 Distributed under the Boost Software License, Version 1.0
 See accompanying file LICENSE_1_0.txt or copy at
 http://www.boost.org/LICENSE_1_0.txt
=============================================================================/]

[section:block_indirect_sort 3.1- block_indirect_sort]


[section:block_introduction 3.1.1- Introduction]

[*BLOCK_INDIRECT_SORT] is a new unstable parallel sort, created and implemented by Francisco Jose Tapia for the Boost Library

[table AlgorithmDescription
[[Algorithm]            [Parallel]  [Stable][Additional Memory]         [Best, average, and worst case]]
[[block_indirect_sort]        [Yes]       [No]    [block_size * num_threads]  [NlogN, NlogN , NlogN]]
]

The block_size is an internal parameter of the algorithm, which in order to achieve the
highest speed, changes according with the size of the objects to sort according to the next table.
The strings use a block_size of 128.

[table BlockSize
[[object size (bytes)]              [1 - 15][16 - 31][32 - 63][64 - 127][128 - 255][256 - 511][512 -]]
[[block_size (number of elements)]  [4096]  [2048]      [1024][768][512][256][128]]
]

The measured results for using 12 threads to sort 100 million random 64 bit numbers are:

[table MemoryUsed
[[Algorithm][Time (secs)][Memory used in MB]]
[[Open MP Parallel Sort]          [1.1990][1564 MB]]
[[Threading Building Blocks (TBB)][1.6411][789 MB]]
[[Block Indirect Sort]            [0.9270][790 MB]]
]

This algorithms [*do not use any other library or utility]. Compiling this library requires a
[*C++11 compliant compiler]. There is no need to link with any external static or dynamic library.

The algorithms use a [*comparison object], in the same way as the standard library sort
algorithms. If you don't define it, the comparison object defaults to std::less, which uses
the < operator internally for comparisons.
If no comparison object is specified, the default class ( std::less<value_t> ) is used.


The algorithms are [*exception safe],  meaning that, the exceptions generated by the algorithms
guarantee the integrity of the objects to sort, but not their relative order. If the exception
is generated inside the objects (in the move or in the copy constructor.. ) the results can be
unpredictable.


You only need to include the file boost/sort/parallel/sort.hpp if you wish to use block_indirect_sort.

``
    #include <boost/sort/sort.hpp>



    template <class iter_t>
    void block_indirect_sort (iter_t first, iter_t last);

    template <class iter_t, typename compare>
    void block_indirect_sort (iter_t first, iter_t last, compare comp);

    template <class iter_t>
    void block_indirect_sort (iter_t first, iter_t last, uint32_t num_thread);

    template <class iter_t, typename compare>
    void block_indirect_sort (iter_t first, iter_t last, compare comp, uint32_t num_thread);
``
This algorithm runs in the namespace boost::sort


[*THREAD SPECIFICATION]

The parallel algorithms have a integer parameter indicating the number of threads to use in the sorting process,
which always is the last value in the call. The default value (if left unspecified) is the number of hardware threads on
the machine where the program is running provided by std::thread::hardware_concurrency().

If the number is 1 or 0, the algorithm uses only 1 thread.

The number of threads passed can be greater than the number of hardware threads. We can pass 100 threads in a machine with 4 hardware threads,
and in the same mode we can pass a variable or  function as (std::thread::hardware_concurrency() / 4 ). If the resulting value is 0, the program is executed with 1 thread

[endsect]


[section:block_internal 3.1.2- Internal Description]


There are two primary categories of parallelization in sorting algorithms.

[*SUBDIVISION ALGORITHMS]

[:Filter the data and generate two or more parts. Each part obtained is
filtered and divided by other threads, until the size of the data to
sort is smaller than a predefined size, then it is sorted by a single
thread. The algorithm most frequently used in the filter and sorting
is quick sort.

These algorithms are fast with a small number of threads, but are inefficient
with a great number of HW (hardware) threads. Examples of this category are
# Intel Threading Building Blocks (TBB)
# Microsoft PPL Parallel Sort.
]

[*MERGING ALGORITHMS]

[:Divide the data in parts, and each part is sorted by a thread. When
the parts are sorted, they are merged to obtain the final results. These algorithms need additional memory for the
merge, usually the same size as the data.

With a small number of threads, these algorithms have similar speed to
than the subdivision algorithms, but with span style=font-weight: bold;many
threads they are much faster/span . Examples of this category are
# GCC Parallel Sort (based on OpenMP)
# Microsoft PPL Parallel Buffered Sort
]

This generates an undesirable duality. With a small number of threads the optimal algorithm is not the optimal for a big number of threads.
For this reason, the software designed for a small machine is inadequate for a big machine and vice versa.
But the main problem for the merging algorithms is the additional memory used, usually of the same size as the data.

[*NEW PARALLEL SORT ALGORITHM (Block Indirect Sort) ]

This algorithm, named Block Indirect Sort, created for processors connected with shared memory, is a hybrid algorithm.
With small number of threads, it is a subdivision algorithm, but with many threads it is a merging algorithms,
 which needs a small  auxiliary memory ( block_size * number of threads).

This algorithm eliminates the duality. You compile your program using the new algorithm. The number of threads to use is evaluated
in each execution. It can be a number, a variable of a expression. When the program runs  with a small number of threads the algorithm
internally uses a subdivision algorithm and has similar performance to  TBB, and when run with many threads,
it internally uses the new algorithm and has the performance of GCC Parallel Sort, with the additional advantage of reduced memory consumption.

[*DESIGN PROCESS ]

The initial idea of this algorithm, was to build a merge algorithm to be fast with many threads, with a low additional memory.

The results obtained in the benchmarks, in speed and memory used, are excellent. These are the results sorting 100000000 randomly generated 64 bit numbers,
on an Intel(R) Core(TM) i7-5820K CPU @ 3.30GHz, with 6 cores and 2 threads by core, and 15M of cache

[table MemoryUsed
[[Algorithm][Time (secs)][Memory used in MB]]
[[Open MP Parallel Sort]          [1.1990][1564 MB]]
[[Threading Building Blocks (TBB)][1.6411][ 789 MB]]
[[Block Indirect Sort]            [0.9270][ 790 MB]]
]

The technique used in the algorithm (indirect blocks) is new, and  had been designed for the algorithm.

The process had been long and very hard, mainly, by the uncertainty about if the ideas are correct and run
so fast as need for to be useful.  This is complicated by the fact that we can’t be sure of the efficiency until the last part
of the code is done and the first benchmark has run.

But it had been a very exciting process, each time a problem is resolved, a new algorithm is designed,
tested …,  and  to see, step by step , the advance of the process.

I discovered many new problems during this process, unknown until now, which forced me to design new internal algorithms to resolve them,
and divide the work in many parts to execute in parallel mode. Due to this, you can find many nice algorithms inside the sorting algorithm written to resolve and parallelize the internal problems.

The best words about this algorithm are expressed by the  [@#linux_parallel benchmarks] results

If you are interested in a detailed description of the algorithm, you can find it here: [@./papaers/block_indirect_sort_en.pdf Block Indirect Sort].


[endsect]

[endsect]



